{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 04. Text Classification\n",
    "\n",
    "\n",
    "This lab is devoted to text classification tasks.\n",
    "- **Part 1 [8 points]** is about very common NLP problem - sentiment analysis.\n",
    "- **Part 2 [7 points]** include tasks on POS tagging and WordEmbeddings.\n",
    "\n",
    "\n",
    "#### Evaluation\n",
    "\n",
    "Each task has its value, **15 points** in total. If you use some open-source code please make sure to include the url.\n",
    "\n",
    "#### How to submit\n",
    "\n",
    "- Name your file according to this convention: `lab04_GroupNo_Surname_Name.ipynb`. If you don't have group number, put `nan` instead.\n",
    "- Attach it to an **email** with **topic** `lab04_GroupNo_Surname_Name.ipynb`\n",
    "- Send it to `cosmic.research.ml@yandex.ru`\n",
    "- Deadline is ` 2022-11-24 23:00:00 +03:00`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Bag of Words vs. Bag of Popcorn [8 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is based on [Bag of Words Meets Bags of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial/data) competition. The goal is to label film reviews as positive or negative. \n",
    "\n",
    "Reviews may look like this:\n",
    "\n",
    "```\n",
    "I dont know why people think this is such a bad movie. Its got a pretty good plot, some good action, and the change of location for Harry does not hurt either. Sure some of its offensive and gratuitous but this is not the only movie like that. Eastwood is in good form as Dirty Harry, and I liked Pat Hingle in this movie as the small town cop. If you liked DIRTY HARRY, then you should see this one, its a lot better than THE DEAD POOL. 4/5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"reviews.tsv\", sep=\"\\t\")\n",
    "reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reviews[\"review\"]\n",
    "y = reviews[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=5000, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to extract features\n",
    "\n",
    "In this part of the assignment we will apply several methods of feature extraction and comapre them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.1 [0.5 point] - Simple BOW** \n",
    "\n",
    "In this task we will build a simple bow representation - without any preprocessing. \n",
    "\n",
    "For this purpose we will use [*CountVectorizer*](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) - a method that transforms text dataset into a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import CountVectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try each of these approaches:\n",
    "- fit vectorizer on X_train, apply to X_train, X_test\n",
    "- fit vectorizer on X_train, apply to X_train; fit on X_test, apply to X_test\n",
    "- fit vectorizer on X, apply to X_train, X_test\n",
    "\n",
    "Report output matrix sizes in each case. \n",
    "- What is the difference? \n",
    "- Which of these approaches is the most fair and correct?\n",
    "\n",
    "Use the most fair and correct one to get `X_train_0` and `X_test_0` - they will be needed for further tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(X_train_0.shape, X_test_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(X_train_0.shape, X_test_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print(X_train_0.shape, X_test_0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.2 [0.5 point] - S___se matrices**\n",
    "\n",
    "What is the data type of `X_train_0` and `X_test_0`? What are those?\n",
    "\n",
    "What differs them from usual np.arrays? Name several types how those special matrices are stored and what they are good for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.3 [1 points] - Training**\n",
    "\n",
    "Train LogisticRegression and Random forest on this data representations.\n",
    "- Compare training time \n",
    "- Compare Accuracy, precision, recall \n",
    "- Plot ROC Curve and calculate ROC AUC (don't forget to predict_proba) \n",
    "- Plot Precision-Recall curve and calculate f1-score (for example, with `plt.subplots(nrows=1, ncols=2)`)\n",
    "- Print the trickiest missclassified objects. Why they were hard to classify? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time as tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, precision_recall_curve, roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=500)\n",
    "lr_model = LogisticRegression(max_iter=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model gives higher scores? Any ideas why? Please suggest 1-2 reasons.\n",
    "\n",
    "*Answer:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More sophisticated feature prerocessing\n",
    "\n",
    "As we have seen, simple BOW can give us some result - it's time to improve it.\n",
    "\n",
    "**Task 1.4 [1 point] - Frequencies calculation**\n",
    "\n",
    "- Calculate top-20 words in train set and test set. *Are they meaningful?*\n",
    "- Import `stopwords` and print some of them. What are those?\n",
    "- Recalculate top-20 words in each set, but exclude stop words.\n",
    "- Does now top-20 include more useful words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import WhitespaceTokenizer, WordPunctTokenizer, TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.5 [1 point] - Word Freqs by class**\n",
    "\n",
    "How do you think, will top100 tokens for positive and negative classes be different? Use data to prove your point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.6 [2 points] - Reducing dimensionality**\n",
    "\n",
    "The goal is to reduce number of features to 15000.\n",
    "\n",
    "Implement the following methods of dimensinality reduction:\n",
    "1. Use CountVectorizer, but leave only 15k most frequent tokens\n",
    "2. Use HashingVectorizer with 15k features\n",
    "3. Use 15k most important features from perspective of previously trained RandomForest\n",
    "\n",
    "*Hints:*\n",
    "- in 1 and 2 you don't have to apply nltk.corpus.stopwords, vectorizers have `stopwords` parameter\n",
    "- in 1 look for `vocabulary` parameter\n",
    "- in 3... remember `lab02`? You may use `X_train_0` and `X_test_0` as input matrices\n",
    "\n",
    "Train LogisticRegression and RandomForest on each dataset and compare ROC AUC scores of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1.7 [2 points] - Token Normalization**\n",
    "\n",
    "Choose the best working method from previous task. Try improve it by applying a token normalization technique.\n",
    "\n",
    "You may use one of normalizers imported below, but feel free to experiment.\n",
    "\n",
    "Do the following:\n",
    "- Apply normalizer to X_train, X_test\n",
    "- Build BOW with CountVectorizer + stopwords. What are the shapes of train and test matrices now?\n",
    "- Reduce dimensionality with the best method from Task 2.6. You may try all of them\n",
    "- Train LR/RF to examine whether ROC AUC or Accuracy was improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer, PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Word Embeddings [7 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of pretrained word embedding models. We suggest using `glove-wiki-gigaword-100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(gensim.downloader.info()['models'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = gensim.downloader.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.1 [1 point] - WordEmbeddings Geometry**\n",
    "\n",
    "As you probably know, vector space of word embeddings has non-trivial geometry: some word relations (like country-capital or single-plural) cab be represented by vectors, like: **(king - man) + woman = queen**\n",
    "\n",
    "<img src=\"https://linkme.ufanet.ru/images/5687a2011b49eb2413912f1c7d0fb0bd.png\" width=600px>\n",
    "\n",
    "Check this statement on words from the above picture with `word_embeddings.most_similar` function. Pay attention to `positive` and `negative` params.\n",
    "\n",
    "Provide **several** examples, make sure to present different relations: some for nouns, some for verbs, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.2 [2 point] - POS analysis**\n",
    "\n",
    "Use POS tagger to calculate most common POS in the dataset. \n",
    "Here you may read about nltk-taggers: [link](https://www.inf.ed.ac.uk/teaching/courses/icl/nltk/tagging.pdf)\n",
    "\n",
    "- If you were to design POS-related weights, how would you do it? \n",
    "- What POS would get the higher weight? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.3 [4 points] - WordEmbeddings**\n",
    "\n",
    "Use dense vector representations to construct vector-representation of each review, then train a model (LR or RF).\n",
    "\n",
    "Compare results of the new model to results of the models above.\n",
    "\n",
    "**Important**\n",
    "- If you just sum embeddings of each token to get an embedding of the whole review, the cost of the task is **[2 points]**\n",
    "- For **[4 points]** you have to use either TF-IDF weight or weights that you designed from POS tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
